{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpenNMT_GRU_ManythingsDataset_Per_Eng.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO1rFkD1pzajJLKQGDrzz9n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoyeBright/Multilingual_Multimodal_Universal_MT/blob/main/OpenNMT_GRU_ManythingsDataset_Per_Eng.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7v22_79M_gBa"
      },
      "source": [
        "### **Install OpenNMT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQgoKyh0-00r",
        "outputId": "9e5a220e-70f4-4fc6-c4c4-abcc7c372cb7"
      },
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install OpenNMT-tf"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.6/dist-packages (20.3.4)\n",
            "Collecting pip\n",
            "  Downloading pip-21.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 6.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 20.3.4\n",
            "    Uninstalling pip-20.3.4:\n",
            "      Successfully uninstalled pip-20.3.4\n",
            "Successfully installed pip-21.0\n",
            "Requirement already satisfied: OpenNMT-tf in /usr/local/lib/python3.6/dist-packages (2.14.0)\n",
            "Requirement already satisfied: tensorflow<2.5,>=2.3 in /usr/local/lib/python3.6/dist-packages (from OpenNMT-tf) (2.4.0)\n",
            "Requirement already satisfied: ctranslate2<2,>=1.7 in /usr/local/lib/python3.6/dist-packages (from OpenNMT-tf) (1.17.1)\n",
            "Requirement already satisfied: rouge<2,>=1.0 in /usr/local/lib/python3.6/dist-packages (from OpenNMT-tf) (1.0.0)\n",
            "Requirement already satisfied: tensorflow-addons<0.13,>=0.12 in /usr/local/lib/python3.6/dist-packages (from OpenNMT-tf) (0.12.0)\n",
            "Requirement already satisfied: pyonmttok<2,>=1.18.1 in /usr/local/lib/python3.6/dist-packages (from OpenNMT-tf) (1.23.0)\n",
            "Requirement already satisfied: pyyaml<5.4,>=5.3 in /usr/local/lib/python3.6/dist-packages (from OpenNMT-tf) (5.3.1)\n",
            "Requirement already satisfied: sacrebleu<2,>=1.4.14 in /usr/local/lib/python3.6/dist-packages (from OpenNMT-tf) (1.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ctranslate2<2,>=1.7->OpenNMT-tf) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rouge<2,>=1.0->OpenNMT-tf) (1.15.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from sacrebleu<2,>=1.4.14->OpenNMT-tf) (2.0.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.3->OpenNMT-tf) (1.12)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.3->OpenNMT-tf) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.3->OpenNMT-tf) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.3->OpenNMT-tf) (3.12.4)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.3->OpenNMT-tf) (0.2.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.3->OpenNMT-tf) (1.6.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.3->OpenNMT-tf) (0.36.2)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.3->OpenNMT-tf) (1.12.1)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.3->OpenNMT-tf) (2.10.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.3->OpenNMT-tf) (0.10.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.3->OpenNMT-tf) (0.3.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.3->OpenNMT-tf) (2.4.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.3->OpenNMT-tf) (1.1.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.3->OpenNMT-tf) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.3->OpenNMT-tf) (3.7.4.3)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.3->OpenNMT-tf) (1.32.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow<2.5,>=2.3->OpenNMT-tf) (51.3.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (1.7.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (0.4.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (1.17.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (3.3.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (4.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (3.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (3.1.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons<0.13,>=0.12->OpenNMT-tf) (2.7.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (3.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SETaKsOD_8Km"
      },
      "source": [
        "### **OpenNMT version**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YM10TZEL_iAa",
        "outputId": "7867edb5-bfe9-4260-b231-bd1426524b65"
      },
      "source": [
        "!onmt-main -v"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-23 20:44:40.413167: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "OpenNMT-tf 2.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga8rMNt8_4si"
      },
      "source": [
        "### **Preparing Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IsQmwY9_1tn",
        "outputId": "7624dda7-b5a0-46fa-a72c-b9c8460fada1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DH3BL5SBd47",
        "outputId": "302539d7-1858-4a67-f591-3011cccccff0"
      },
      "source": [
        "!wget \"https://www.manythings.org/anki/pes-eng.zip\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-23 17:06:03--  https://www.manythings.org/anki/pes-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 104.21.55.222, 172.67.173.198, 2606:4700:3036::ac43:adc6, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|104.21.55.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 112553 (110K) [application/zip]\n",
            "Saving to: ‘pes-eng.zip’\n",
            "\n",
            "pes-eng.zip         100%[===================>] 109.92K   527KB/s    in 0.2s    \n",
            "\n",
            "2021-01-23 17:06:04 (527 KB/s) - ‘pes-eng.zip’ saved [112553/112553]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceM7koUGBh03",
        "outputId": "93639a6e-3711-4d8c-bbea-b0fa3f60b0b7"
      },
      "source": [
        "!unzip pes-eng.zip -d \"/content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  pes-eng.zip\n",
            "  inflating: /content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/_about.txt  \n",
            "  inflating: /content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/pes.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJLoYhK3CT1I"
      },
      "source": [
        "path = \"/content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/pes.txt\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3I2y1EfFCXTN",
        "outputId": "084a71cf-f3dc-40a5-f516-40ee0242f13e"
      },
      "source": [
        "f = open(path, \"r\")\n",
        "print(f.read(978)) "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Who?\tچه کسی؟\tCC-BY 2.0 (France) Attribution: tatoeba.org #2083030 (CK) & #4746184 (mahdiye)\n",
            "Go on.\tادامه بده ( ادامه دادن )\tCC-BY 2.0 (France) Attribution: tatoeba.org #2230774 (CK) & #6669169 (arashorosia)\n",
            "Smile.\tلبخند بزن.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2764108 (CK) & #4746196 (mahdiye)\n",
            "Attack!\tحمله!\tCC-BY 2.0 (France) Attribution: tatoeba.org #1972610 (CK) & #4746181 (mahdiye)\n",
            "Got it!\tگرفتم!\tCC-BY 2.0 (France) Attribution: tatoeba.org #320484 (CM) & #888645 (mahdiye)\n",
            "I know.\tمن می دانم.\tCC-BY 2.0 (France) Attribution: tatoeba.org #319990 (CK) & #888643 (mahdiye)\n",
            "Listen.\tگوش کن.\tCC-BY 2.0 (France) Attribution: tatoeba.org #1913088 (CK) & #4746178 (mahdiye)\n",
            "Really?\tواقعا؟\tCC-BY 2.0 (France) Attribution: tatoeba.org #373216 (kotobaboke) & #5118169 (Hussein64)\n",
            "Really?\tجدا؟\tCC-BY 2.0 (France) Attribution: tatoeba.org #373216 (kotobaboke) & #5118171 (Hussein64)\n",
            "Why me?\tچرا من؟\tCC-BY 2.0 (France) Attribution: tatoeba.org #24958 (CK) & #4746261 (mahdiye)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKqp5kTFDbeJ"
      },
      "source": [
        "import re"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4neW1EyUDUc8"
      },
      "source": [
        "text_file = open(\"/content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/English.txt\", \"w\")\n",
        "text_file2 = open(\"/content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/Persian.txt\", \"w\")\n",
        "\n",
        "f = open(path, \"r\")\n",
        "for r in f:\n",
        "  text_file.write(re.split(r'\\t+', r)[0]+\"\\n\") # English txt\n",
        "  text_file2.write(re.split(r'\\t+', r)[1]+\"\\n\") # Persian txt"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDVmh-VeHGEM"
      },
      "source": [
        "text_file.close()\n",
        "text_file2.close()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNBo8pqgIC3-"
      },
      "source": [
        "### **Dataset Splits: Train, Validation, Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr4T9jblIB3p"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0ysvjQTV_zU"
      },
      "source": [
        "English = np.genfromtxt(\"/content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/English.txt\", dtype='str', delimiter=\"\\n\")\n",
        "Persian = np.genfromtxt(\"/content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/Persian.txt\", dtype='str', delimiter=\"\\n\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFwg9c_wapFC",
        "outputId": "3e219f04-3105-487e-c912-9dc4605dccc1"
      },
      "source": [
        "print(English[:10]) #target\n",
        "print(Persian[:10]) #source"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Who?' 'Go on.' 'Smile.' 'Attack!' 'Got it!' 'I know.' 'Listen.'\n",
            " 'Really?' 'Really?' 'Why me?']\n",
            "['چه کسی؟' 'ادامه بده ( ادامه دادن )' 'لبخند بزن.' 'حمله!' 'گرفتم!'\n",
            " 'من می دانم.' 'گوش کن.' 'واقعا؟' 'جدا؟' 'چرا من؟']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ydw7VpsQ-jb"
      },
      "source": [
        "src_train, src_test, tgt_train, tgt_test = train_test_split(Persian, English, test_size=0.2, random_state=1)\n",
        "\n",
        "src_train, src_val, tgt_train, tgt_val = train_test_split(src_train, tgt_train, test_size=0.25, random_state=1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUw6Oqg7CZhs",
        "outputId": "e79161ce-c96b-493b-cd23-14dd9a0709e4"
      },
      "source": [
        "print(\"Source (Train, Test, Val):\" , src_train.shape[0], src_test.shape[0], src_val.shape[0])\n",
        "print(\"Target (Train, Test, Va)l:\" , tgt_train.shape[0], tgt_test.shape[0], tgt_val.shape[0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Source (Train, Test, Val): 1365 455 455\n",
            "Target (Train, Test, Va)l: 1365 455 455\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbYs6MaRKBCJ"
      },
      "source": [
        "np.savetxt(\"/content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/src-train.txt\", src_train, encoding=\"UTF-8\", fmt = '%s')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ob34DZd4Ljs8"
      },
      "source": [
        "np.savetxt(\"/content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/tgt-train.txt\", tgt_train, encoding=\"UTF-8\", fmt = '%s')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYwmR32kL2fm"
      },
      "source": [
        "np.savetxt(\"/content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/src-test.txt\", src_test, encoding=\"UTF-8\", fmt = '%s')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6-CK1OSMb3g"
      },
      "source": [
        "np.savetxt(\"/content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/tgt-test.txt\", tgt_test, encoding=\"UTF-8\", fmt = '%s')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hPUYKF5MnX0"
      },
      "source": [
        "np.savetxt(\"/content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/src-val.txt\", src_val, encoding=\"UTF-8\", fmt = '%s')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibqQty3TM1iJ"
      },
      "source": [
        "np.savetxt(\"/content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/tgt-val.txt\", tgt_val, encoding=\"UTF-8\", fmt = '%s')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WL3qB-VvfE_B"
      },
      "source": [
        "### **Creating Vocabulary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkFnxpyyfH37",
        "outputId": "d152f982-f225-4386-8666-78165fa562be"
      },
      "source": [
        "!pip install sacremoses # used as an English tokenizer"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (0.0.43)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from sacremoses) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sacremoses) (4.41.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses) (1.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3HUS15KrmMq"
      },
      "source": [
        "### **Generate English vocabulary from raw training files with on-the-fly tokenization (online)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBqzZ5ZQmy43",
        "outputId": "9e0d5db0-8690-4bdb-9ef8-ef0951ccf68c"
      },
      "source": [
        "!onmt-build-vocab --size 50000 --save_vocab /content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/data/tgt-vocab.txt /content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/tgt-train.txt"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-23 20:47:19.747617: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-01-23 20:47:22.068379: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-01-23 20:47:22.070279: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-01-23 20:47:22.081348: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-01-23 20:47:22.081421: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (dced393d028e): /proc/driver/nvidia/version does not exist\n",
            "2021-01-23 20:47:22.082034: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIvr97rwu580"
      },
      "source": [
        "### **Generate Persian vocabulary from customized tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkCbbdUyDCUg",
        "outputId": "9ffa2856-a40d-4f3b-912a-fb20ba5b3c98"
      },
      "source": [
        "from __future__ import unicode_literals\n",
        "!pip install hazm\n",
        "from hazm import *"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hazm in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: nltk==3.3 in /usr/local/lib/python3.6/dist-packages (from hazm) (3.3)\n",
            "Requirement already satisfied: libwapiti>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from hazm) (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk==3.3->hazm) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6Dx1x3xFWnD"
      },
      "source": [
        "def preprocess_persian_sentence(w):\n",
        "  normalizer = Normalizer() # Persian normalizer instance (Hazm)\n",
        "  w = normalizer.normalize(w)\n",
        "  w = word_tokenize(w)\n",
        "  return w"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MmjzTUnLtyP"
      },
      "source": [
        "import io\n",
        "\n",
        "text_file = \"/content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/src-train.txt\"\n",
        "\n",
        "tokenized_file = \"/content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/test.txt\"\n",
        "\n",
        "lines = io.open(text_file, encoding=\"UTF-8\").read()\n",
        "\n",
        "tokenized_array = []\n",
        "\n",
        "for line in lines.splitlines():\n",
        "  # print(preprocess_persian_sentence(line))\n",
        "  # print(type(preprocess_persian_sentence(line)))\n",
        "  # print(\" \".join(str(x) for x in preprocess_persian_sentence(line)))\n",
        "  tokenized_array.append(\" \".join(str(x) for x in preprocess_persian_sentence(line)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-Eq1098Bhg2"
      },
      "source": [
        "# print(tokenized_array)\n",
        "with open(tokenized_file, 'w') as f:\n",
        "    for item in tokenized_array:\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": 39,
      "outputs": []
    }
  ]
}