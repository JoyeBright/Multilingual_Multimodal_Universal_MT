{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpenNMT_GRU_ManythingsDataset_Per_Eng.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMzCmYeo8ou5OISNCqgv259",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoyeBright/Multilingual_Multimodal_Universal_MT/blob/main/OpenNMT_GRU_ManythingsDataset_Per_Eng.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7v22_79M_gBa"
      },
      "source": [
        "### **Install OpenNMT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQgoKyh0-00r",
        "outputId": "84e94d83-55b0-4f7a-f3b2-ec111ec6a6cb"
      },
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install OpenNMT-tf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/47/58b9f3e6f611dfd17fb8bd9ed3e6f93b7ee662fb85bdfee3565e8979ddf7/pip-21.0-py3-none-any.whl (1.5MB)\n",
            "\r\u001b[K     |▏                               | 10kB 30.0MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 34.4MB/s eta 0:00:01\r\u001b[K     |▋                               | 30kB 25.7MB/s eta 0:00:01\r\u001b[K     |▉                               | 40kB 29.6MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 30.3MB/s eta 0:00:01\r\u001b[K     |█▎                              | 61kB 32.8MB/s eta 0:00:01\r\u001b[K     |█▌                              | 71kB 20.8MB/s eta 0:00:01\r\u001b[K     |█▊                              | 81kB 20.9MB/s eta 0:00:01\r\u001b[K     |██                              | 92kB 19.5MB/s eta 0:00:01\r\u001b[K     |██▏                             | 102kB 20.4MB/s eta 0:00:01\r\u001b[K     |██▍                             | 112kB 20.4MB/s eta 0:00:01\r\u001b[K     |██▋                             | 122kB 20.4MB/s eta 0:00:01\r\u001b[K     |██▊                             | 133kB 20.4MB/s eta 0:00:01\r\u001b[K     |███                             | 143kB 20.4MB/s eta 0:00:01\r\u001b[K     |███▏                            | 153kB 20.4MB/s eta 0:00:01\r\u001b[K     |███▍                            | 163kB 20.4MB/s eta 0:00:01\r\u001b[K     |███▋                            | 174kB 20.4MB/s eta 0:00:01\r\u001b[K     |███▉                            | 184kB 20.4MB/s eta 0:00:01\r\u001b[K     |████                            | 194kB 20.4MB/s eta 0:00:01\r\u001b[K     |████▎                           | 204kB 20.4MB/s eta 0:00:01\r\u001b[K     |████▌                           | 215kB 20.4MB/s eta 0:00:01\r\u001b[K     |████▊                           | 225kB 20.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 235kB 20.4MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 245kB 20.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 256kB 20.4MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 266kB 20.4MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 276kB 20.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 286kB 20.4MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 296kB 20.4MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 307kB 20.4MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 317kB 20.4MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 327kB 20.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 337kB 20.4MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 348kB 20.4MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 358kB 20.4MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 368kB 20.4MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 378kB 20.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 389kB 20.4MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 399kB 20.4MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 409kB 20.4MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 419kB 20.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 430kB 20.4MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 440kB 20.4MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 450kB 20.4MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 460kB 20.4MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 471kB 20.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 481kB 20.4MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 491kB 20.4MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 501kB 20.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 512kB 20.4MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 522kB 20.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 532kB 20.4MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 542kB 20.4MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 552kB 20.4MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 563kB 20.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 573kB 20.4MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 583kB 20.4MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 593kB 20.4MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 604kB 20.4MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 614kB 20.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 624kB 20.4MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 634kB 20.4MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 645kB 20.4MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 655kB 20.4MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 665kB 20.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 675kB 20.4MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 686kB 20.4MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 696kB 20.4MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 706kB 20.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 716kB 20.4MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 727kB 20.4MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 737kB 20.4MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 747kB 20.4MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 757kB 20.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 768kB 20.4MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 778kB 20.4MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 788kB 20.4MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 798kB 20.4MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 808kB 20.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 819kB 20.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 829kB 20.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 839kB 20.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 849kB 20.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 860kB 20.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 870kB 20.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 880kB 20.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 890kB 20.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 901kB 20.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 911kB 20.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 921kB 20.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 931kB 20.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 942kB 20.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 952kB 20.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 962kB 20.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 972kB 20.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 983kB 20.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 993kB 20.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.0MB 20.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.0MB 20.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.0MB 20.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.0MB 20.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.0MB 20.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.1MB 20.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.1MB 20.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.1MB 20.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.1MB 20.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.1MB 20.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.1MB 20.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.1MB 20.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.1MB 20.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.1MB 20.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.1MB 20.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.2MB 20.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.2MB 20.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.2MB 20.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.2MB 20.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.2MB 20.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.2MB 20.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.2MB 20.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.2MB 20.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.2MB 20.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2MB 20.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.3MB 20.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.3MB 20.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.3MB 20.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.3MB 20.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.3MB 20.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.3MB 20.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.3MB 20.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.3MB 20.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.3MB 20.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.4MB 20.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.4MB 20.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.4MB 20.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.4MB 20.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.4MB 20.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.4MB 20.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.4MB 20.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.4MB 20.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.4MB 20.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.4MB 20.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.5MB 20.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.5MB 20.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.5MB 20.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.5MB 20.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.5MB 20.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.5MB 20.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.5MB 20.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.5MB 20.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5MB 20.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5MB 20.4MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "Successfully installed pip-21.0\n",
            "Collecting OpenNMT-tf\n",
            "  Downloading OpenNMT_tf-2.14.0-py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 21.6 MB/s \n",
            "\u001b[?25hCollecting rouge<2,>=1.0\n",
            "  Downloading rouge-1.0.0-py3-none-any.whl (14 kB)\n",
            "Collecting sacrebleu<2,>=1.4.14\n",
            "  Downloading sacrebleu-1.5.0-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting ctranslate2<2,>=1.7\n",
            "  Downloading ctranslate2-1.17.1-cp36-cp36m-manylinux2014_x86_64.whl (75.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 75.5 MB 18 kB/s \n",
            "\u001b[?25hCollecting pyyaml<5.4,>=5.3\n",
            "  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n",
            "\u001b[K     |████████████████████████████████| 269 kB 84.0 MB/s \n",
            "\u001b[?25hCollecting tensorflow-addons<0.13,>=0.12\n",
            "  Downloading tensorflow_addons-0.12.0-cp36-cp36m-manylinux2010_x86_64.whl (703 kB)\n",
            "\u001b[K     |████████████████████████████████| 703 kB 58.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<2.5,>=2.3 in /usr/local/lib/python3.6/dist-packages (from OpenNMT-tf) (2.4.0)\n",
            "Collecting pyonmttok<2,>=1.18.1\n",
            "  Downloading pyonmttok-1.23.0-cp36-cp36m-manylinux1_x86_64.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 45.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ctranslate2<2,>=1.7->OpenNMT-tf) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rouge<2,>=1.0->OpenNMT-tf) (1.15.0)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.1.0-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.3->OpenNMT-tf) (0.36.2)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.3->OpenNMT-tf) (1.6.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.3->OpenNMT-tf) (0.10.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.3->OpenNMT-tf) (2.10.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.3->OpenNMT-tf) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.3->OpenNMT-tf) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.3->OpenNMT-tf) (3.7.4.3)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.3->OpenNMT-tf) (1.32.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.3->OpenNMT-tf) (0.3.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.3->OpenNMT-tf) (3.12.4)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.3->OpenNMT-tf) (1.12)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.3->OpenNMT-tf) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.3->OpenNMT-tf) (2.4.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.3->OpenNMT-tf) (2.4.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.3->OpenNMT-tf) (1.12.1)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.3->OpenNMT-tf) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow<2.5,>=2.3->OpenNMT-tf) (51.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (1.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (3.3.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (0.4.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (4.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (3.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (3.1.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons<0.13,>=0.12->OpenNMT-tf) (2.7.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow<2.5,>=2.3->OpenNMT-tf) (3.4.0)\n",
            "Building wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44621 sha256=f89031ed89b2789faa9877a839f23cfc65c6f9f96e6b717a3ac8a67fb5fddfe2\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/9d/ad/2ee53cf262cba1ffd8afe1487eef788ea3f260b7e6232a80fc\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: portalocker, tensorflow-addons, sacrebleu, rouge, pyyaml, pyonmttok, ctranslate2, OpenNMT-tf\n",
            "  Attempting uninstall: tensorflow-addons\n",
            "    Found existing installation: tensorflow-addons 0.8.3\n",
            "    Uninstalling tensorflow-addons-0.8.3:\n",
            "      Successfully uninstalled tensorflow-addons-0.8.3\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed OpenNMT-tf-2.14.0 ctranslate2-1.17.1 portalocker-2.1.0 pyonmttok-1.23.0 pyyaml-5.3.1 rouge-1.0.0 sacrebleu-1.5.0 tensorflow-addons-0.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SETaKsOD_8Km"
      },
      "source": [
        "### **OpenNMT version**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YM10TZEL_iAa",
        "outputId": "af1eb18d-535a-41b5-a531-d1a223000ee3"
      },
      "source": [
        "!onmt-main -v"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-25 09:43:22.488662: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "OpenNMT-tf 2.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga8rMNt8_4si"
      },
      "source": [
        "### **Preparing Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IsQmwY9_1tn",
        "outputId": "da6ea02a-7c68-43a6-a7df-3bfba26548cf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DH3BL5SBd47",
        "outputId": "302539d7-1858-4a67-f591-3011cccccff0"
      },
      "source": [
        "!wget \"https://www.manythings.org/anki/pes-eng.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-23 17:06:03--  https://www.manythings.org/anki/pes-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 104.21.55.222, 172.67.173.198, 2606:4700:3036::ac43:adc6, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|104.21.55.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 112553 (110K) [application/zip]\n",
            "Saving to: ‘pes-eng.zip’\n",
            "\n",
            "pes-eng.zip         100%[===================>] 109.92K   527KB/s    in 0.2s    \n",
            "\n",
            "2021-01-23 17:06:04 (527 KB/s) - ‘pes-eng.zip’ saved [112553/112553]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceM7koUGBh03",
        "outputId": "93639a6e-3711-4d8c-bbea-b0fa3f60b0b7"
      },
      "source": [
        "!unzip pes-eng.zip -d \"/content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  pes-eng.zip\n",
            "  inflating: /content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/_about.txt  \n",
            "  inflating: /content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/pes.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJLoYhK3CT1I"
      },
      "source": [
        "path = \"/content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/pes.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3I2y1EfFCXTN",
        "outputId": "084a71cf-f3dc-40a5-f516-40ee0242f13e"
      },
      "source": [
        "f = open(path, \"r\")\n",
        "print(f.read(978)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Who?\tچه کسی؟\tCC-BY 2.0 (France) Attribution: tatoeba.org #2083030 (CK) & #4746184 (mahdiye)\n",
            "Go on.\tادامه بده ( ادامه دادن )\tCC-BY 2.0 (France) Attribution: tatoeba.org #2230774 (CK) & #6669169 (arashorosia)\n",
            "Smile.\tلبخند بزن.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2764108 (CK) & #4746196 (mahdiye)\n",
            "Attack!\tحمله!\tCC-BY 2.0 (France) Attribution: tatoeba.org #1972610 (CK) & #4746181 (mahdiye)\n",
            "Got it!\tگرفتم!\tCC-BY 2.0 (France) Attribution: tatoeba.org #320484 (CM) & #888645 (mahdiye)\n",
            "I know.\tمن می دانم.\tCC-BY 2.0 (France) Attribution: tatoeba.org #319990 (CK) & #888643 (mahdiye)\n",
            "Listen.\tگوش کن.\tCC-BY 2.0 (France) Attribution: tatoeba.org #1913088 (CK) & #4746178 (mahdiye)\n",
            "Really?\tواقعا؟\tCC-BY 2.0 (France) Attribution: tatoeba.org #373216 (kotobaboke) & #5118169 (Hussein64)\n",
            "Really?\tجدا؟\tCC-BY 2.0 (France) Attribution: tatoeba.org #373216 (kotobaboke) & #5118171 (Hussein64)\n",
            "Why me?\tچرا من؟\tCC-BY 2.0 (France) Attribution: tatoeba.org #24958 (CK) & #4746261 (mahdiye)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKqp5kTFDbeJ"
      },
      "source": [
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4neW1EyUDUc8"
      },
      "source": [
        "text_file = open(\"/content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/English.txt\", \"w\")\n",
        "text_file2 = open(\"/content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/Persian.txt\", \"w\")\n",
        "\n",
        "f = open(path, \"r\")\n",
        "for r in f:\n",
        "  text_file.write(re.split(r'\\t+', r)[0]+\"\\n\") # English txt\n",
        "  text_file2.write(re.split(r'\\t+', r)[1]+\"\\n\") # Persian txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDVmh-VeHGEM"
      },
      "source": [
        "text_file.close()\n",
        "text_file2.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNBo8pqgIC3-"
      },
      "source": [
        "### **Dataset Splits: Train, Validation, Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr4T9jblIB3p"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0ysvjQTV_zU"
      },
      "source": [
        "English = np.genfromtxt(\"/content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/English.txt\", dtype='str', delimiter=\"\\n\")\n",
        "Persian = np.genfromtxt(\"/content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/Persian.txt\", dtype='str', delimiter=\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFwg9c_wapFC",
        "outputId": "3e219f04-3105-487e-c912-9dc4605dccc1"
      },
      "source": [
        "print(English[:10]) #target\n",
        "print(Persian[:10]) #source"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Who?' 'Go on.' 'Smile.' 'Attack!' 'Got it!' 'I know.' 'Listen.'\n",
            " 'Really?' 'Really?' 'Why me?']\n",
            "['چه کسی؟' 'ادامه بده ( ادامه دادن )' 'لبخند بزن.' 'حمله!' 'گرفتم!'\n",
            " 'من می دانم.' 'گوش کن.' 'واقعا؟' 'جدا؟' 'چرا من؟']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ydw7VpsQ-jb"
      },
      "source": [
        "src_train, src_test, tgt_train, tgt_test = train_test_split(Persian, English, test_size=0.2, random_state=1)\n",
        "\n",
        "src_train, src_val, tgt_train, tgt_val = train_test_split(src_train, tgt_train, test_size=0.25, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUw6Oqg7CZhs",
        "outputId": "e79161ce-c96b-493b-cd23-14dd9a0709e4"
      },
      "source": [
        "print(\"Source (Train, Test, Val):\" , src_train.shape[0], src_test.shape[0], src_val.shape[0])\n",
        "print(\"Target (Train, Test, Va)l:\" , tgt_train.shape[0], tgt_test.shape[0], tgt_val.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Source (Train, Test, Val): 1365 455 455\n",
            "Target (Train, Test, Va)l: 1365 455 455\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbYs6MaRKBCJ"
      },
      "source": [
        "np.savetxt(\"/content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/src-train.txt\", src_train, encoding=\"UTF-8\", fmt = '%s')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ob34DZd4Ljs8"
      },
      "source": [
        "np.savetxt(\"/content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/tgt-train.txt\", tgt_train, encoding=\"UTF-8\", fmt = '%s')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYwmR32kL2fm"
      },
      "source": [
        "np.savetxt(\"/content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/src-test.txt\", src_test, encoding=\"UTF-8\", fmt = '%s')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6-CK1OSMb3g"
      },
      "source": [
        "np.savetxt(\"/content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/tgt-test.txt\", tgt_test, encoding=\"UTF-8\", fmt = '%s')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hPUYKF5MnX0"
      },
      "source": [
        "np.savetxt(\"/content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/src-val.txt\", src_val, encoding=\"UTF-8\", fmt = '%s')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibqQty3TM1iJ"
      },
      "source": [
        "np.savetxt(\"/content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/tgt-val.txt\", tgt_val, encoding=\"UTF-8\", fmt = '%s')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WL3qB-VvfE_B"
      },
      "source": [
        "### **Creating Vocabulary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkFnxpyyfH37",
        "outputId": "fbe058f4-99eb-47df-efe0-430d8748ac57"
      },
      "source": [
        "!pip install sacremoses # used as an English tokenizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.43.tar.gz (883 kB)\n",
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 37.8 MB/s eta 0:00:01\r\u001b[K     |▊                               | 20 kB 42.9 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 30 kB 29.3 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 40 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 51 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 61 kB 32.9 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 71 kB 19.8 MB/s eta 0:00:01\r\u001b[K     |███                             | 81 kB 21.0 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 92 kB 19.5 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 102 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |████                            | 112 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 122 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 133 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 143 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 153 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████                          | 163 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 174 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 184 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███████                         | 194 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 204 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 215 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 225 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 235 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 245 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 256 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 266 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 276 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 286 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 296 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 307 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 317 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 327 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 337 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 348 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 358 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 368 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 378 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 389 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 399 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 409 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 419 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 430 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 440 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 450 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 460 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 471 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 481 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 491 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 501 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 512 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 522 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 532 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 542 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 552 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 563 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 573 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 583 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 593 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 604 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 614 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 624 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 634 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 645 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 655 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 665 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 675 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 686 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 696 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 706 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 716 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 727 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 737 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 747 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 757 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 768 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 778 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 788 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 798 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 808 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 819 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 829 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 839 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 849 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 860 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 870 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 880 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 883 kB 19.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from sacremoses) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses) (1.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sacremoses) (4.41.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893258 sha256=56cf0b20cbbaf9aed06ea992b72194d765c9cf088b6dde511dd113ceaac25fac\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/25/98/cdea9c79b2d9a22ccc59540b1784b67f06b633378e97f58da2\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses\n",
            "Successfully installed sacremoses-0.0.43\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3HUS15KrmMq"
      },
      "source": [
        "### **Generate English vocabulary from raw training files with on-the-fly tokenization (online)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBqzZ5ZQmy43",
        "outputId": "cc71a081-48c6-41c7-8dd7-6b24a7db69f6"
      },
      "source": [
        "!onmt-build-vocab --size 50000 --save_vocab /content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/data/tgt-vocab.txt /content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/tgt-train.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-23 21:17:37.995452: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-01-23 21:17:40.292901: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-01-23 21:17:40.293820: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-01-23 21:17:40.304732: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-01-23 21:17:40.304789: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (dced393d028e): /proc/driver/nvidia/version does not exist\n",
            "2021-01-23 21:17:40.305329: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIvr97rwu580"
      },
      "source": [
        "### **Generate Persian vocabulary from customized tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkCbbdUyDCUg",
        "outputId": "9ffa2856-a40d-4f3b-912a-fb20ba5b3c98"
      },
      "source": [
        "from __future__ import unicode_literals\n",
        "!pip install hazm\n",
        "from hazm import *"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hazm in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: nltk==3.3 in /usr/local/lib/python3.6/dist-packages (from hazm) (3.3)\n",
            "Requirement already satisfied: libwapiti>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from hazm) (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk==3.3->hazm) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6Dx1x3xFWnD"
      },
      "source": [
        "def preprocess_persian_sentence(w):\n",
        "  normalizer = Normalizer() # Persian normalizer instance (Hazm)\n",
        "  w = normalizer.normalize(w)\n",
        "  w = word_tokenize(w)\n",
        "  return w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MmjzTUnLtyP"
      },
      "source": [
        "import io\n",
        "\n",
        "text_file = \"/content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/src-train.txt\"\n",
        "\n",
        "tokenized_file = \"/content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/test.txt\"\n",
        "\n",
        "lines = io.open(text_file, encoding=\"UTF-8\").read()\n",
        "\n",
        "tokenized_array = []\n",
        "\n",
        "for line in lines.splitlines():\n",
        "  # print(preprocess_persian_sentence(line))\n",
        "  # print(type(preprocess_persian_sentence(line)))\n",
        "  print(\" \".join(str(x) for x in preprocess_persian_sentence(line)))\n",
        "  tokenized_array.append(\" \".join(str(x) for x in preprocess_persian_sentence(line)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-Eq1098Bhg2"
      },
      "source": [
        "# print(tokenized_array)\n",
        "with open(tokenized_file, 'w') as f:\n",
        "    for item in tokenized_array:\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDpNYETiGfrt"
      },
      "source": [
        "**Generating vocabulary from Persian tokenized sentences**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_X605rJzGcyp",
        "outputId": "002ba7bd-c037-44e9-9631-aca78af50bea"
      },
      "source": [
        "!onmt-build-vocab --size 50000 --save_vocab /content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/data/src-vocab.txt /content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/src-test.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-23 21:17:11.832052: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-01-23 21:17:14.133504: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-01-23 21:17:14.134482: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-01-23 21:17:14.145235: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-01-23 21:17:14.145300: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (dced393d028e): /proc/driver/nvidia/version does not exist\n",
            "2021-01-23 21:17:14.145824: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-m3DQIXHK4f"
      },
      "source": [
        "### **Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qhvgb_mg-E5b"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYcogt2FAwE4",
        "outputId": "e07cd87a-aaa9-4343-e987-3335aeb0759d"
      },
      "source": [
        "!onmt-main -h"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-25 10:07:20.291675: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "usage: onmt-main [-h] [-v] --config CONFIG [CONFIG ...] [--auto_config]\n",
            "                 [--model_type {GPT2Small,ListenAttendSpell,LstmCnnCrfTagger,LuongAttention,NMTBigV1,NMTMediumV1,NMTSmallV1,Transformer,TransformerBase,TransformerBaseRelative,TransformerBig,TransformerBigRelative,TransformerRelative}]\n",
            "                 [--model MODEL] [--run_dir RUN_DIR] [--data_dir DATA_DIR]\n",
            "                 [--checkpoint_path CHECKPOINT_PATH]\n",
            "                 [--log_level {CRITICAL,ERROR,WARNING,INFO,DEBUG,NOTSET}]\n",
            "                 [--seed SEED] [--gpu_allow_growth]\n",
            "                 [--intra_op_parallelism_threads INTRA_OP_PARALLELISM_THREADS]\n",
            "                 [--inter_op_parallelism_threads INTER_OP_PARALLELISM_THREADS]\n",
            "                 [--mixed_precision] [--eager_execution]\n",
            "                 {train,eval,infer,export,score,average_checkpoints,update_vocab}\n",
            "                 ...\n",
            "\n",
            "positional arguments:\n",
            "  {train,eval,infer,export,score,average_checkpoints,update_vocab}\n",
            "                        Run type.\n",
            "    train               Training.\n",
            "    eval                Evaluation.\n",
            "    infer               Inference.\n",
            "    export              Model export.\n",
            "    score               Scoring.\n",
            "    average_checkpoints\n",
            "                        Checkpoint averaging.\n",
            "    update_vocab        Update model vocabularies in checkpoint.\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  -v, --version         show program's version number and exit\n",
            "  --config CONFIG [CONFIG ...]\n",
            "                        List of configuration files. (default: None)\n",
            "  --auto_config         Enable automatic configuration values. (default:\n",
            "                        False)\n",
            "  --model_type {GPT2Small,ListenAttendSpell,LstmCnnCrfTagger,LuongAttention,NMTBigV1,NMTMediumV1,NMTSmallV1,Transformer,TransformerBase,TransformerBaseRelative,TransformerBig,TransformerBigRelative,TransformerRelative}\n",
            "                        Model type from the catalog. (default: )\n",
            "  --model MODEL         Custom model configuration file. (default: )\n",
            "  --run_dir RUN_DIR     If set, model_dir will be created relative to this\n",
            "                        location. (default: )\n",
            "  --data_dir DATA_DIR   If set, data files are expected to be relative to this\n",
            "                        location. (default: )\n",
            "  --checkpoint_path CHECKPOINT_PATH\n",
            "                        Specific checkpoint or model directory to load (when a\n",
            "                        directory is set, the latest checkpoint is used).\n",
            "                        (default: None)\n",
            "  --log_level {CRITICAL,ERROR,WARNING,INFO,DEBUG,NOTSET}\n",
            "                        Logs verbosity. (default: INFO)\n",
            "  --seed SEED           Random seed. (default: None)\n",
            "  --gpu_allow_growth    Allocate GPU memory dynamically. (default: False)\n",
            "  --intra_op_parallelism_threads INTRA_OP_PARALLELISM_THREADS\n",
            "                        Number of intra op threads (0 means the system picks\n",
            "                        an appropriate number). (default: 0)\n",
            "  --inter_op_parallelism_threads INTER_OP_PARALLELISM_THREADS\n",
            "                        Number of inter op threads (0 means the system picks\n",
            "                        an appropriate number). (default: 0)\n",
            "  --mixed_precision     Enable mixed precision. (default: False)\n",
            "  --eager_execution     Enable TensorFlow eager execution. (default: False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2L9LEIfHNI1",
        "outputId": "7e08c75b-c06b-4f5f-ece7-1847813cf410"
      },
      "source": [
        "!onmt-main --model_type LuongAttention --config /content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/config/config_train_rnn.yml --auto_config train --with_eval"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-25 10:33:33.767138: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-01-25 10:33:35.493717: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-01-25 10:33:35.494787: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-01-25 10:33:35.551857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-25 10:33:35.552417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-01-25 10:33:35.552453: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-01-25 10:33:35.758345: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
            "2021-01-25 10:33:35.758436: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
            "2021-01-25 10:33:35.908034: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-01-25 10:33:35.926713: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-01-25 10:33:36.199787: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-01-25 10:33:36.229563: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-01-25 10:33:36.746190: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-01-25 10:33:36.746355: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-25 10:33:36.746967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-25 10:33:36.750241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "INFO:tensorflow:Using OpenNMT-tf version 2.14.0\n",
            "INFO:tensorflow:Using model:\n",
            "(model): LuongAttention(\n",
            "  (examples_inputter): SequenceToSequenceInputter(\n",
            "    (features_inputter): WordEmbedder()\n",
            "    (labels_inputter): WordEmbedder()\n",
            "    (inputters): ListWrapper(\n",
            "      (0): WordEmbedder()\n",
            "      (1): WordEmbedder()\n",
            "    )\n",
            "  )\n",
            "  (encoder): RNNEncoder(\n",
            "    (rnn): RNN(\n",
            "      (rnn): RNN(\n",
            "        (cell): StackedRNNCells(\n",
            "          (cells): ListWrapper(\n",
            "            (0): RNNCellWrapper(\n",
            "              (layer): LSTMCell(1000)\n",
            "              (cell): LSTMCell(1000)\n",
            "            )\n",
            "            (1): RNNCellWrapper(\n",
            "              (layer): LSTMCell(1000)\n",
            "              (cell): LSTMCell(1000)\n",
            "            )\n",
            "            (2): RNNCellWrapper(\n",
            "              (layer): LSTMCell(1000)\n",
            "              (cell): LSTMCell(1000)\n",
            "            )\n",
            "            (3): RNNCellWrapper(\n",
            "              (layer): LSTMCell(1000)\n",
            "              (cell): LSTMCell(1000)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (reducer): ConcatReducer()\n",
            "    )\n",
            "  )\n",
            "  (decoder): AttentionalRNNDecoder(\n",
            "    (bridge): CopyBridge()\n",
            "    (attention_mechanism): LuongAttention(\n",
            "      (memory_layer): Dense(1000)\n",
            "    )\n",
            "    (cell): AttentionWrapper()\n",
            "  )\n",
            ")\n",
            "\n",
            "INFO:tensorflow:Using parameters:\n",
            "data:\n",
            "  eval_features_file: /content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/src-val.txt\n",
            "  eval_labels_file: /content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/tgt-val.txt\n",
            "  source_vocabulary: /content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/data/src-vocab.txt\n",
            "  target_vocabulary: /content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/data/tgt-vocab.txt\n",
            "  train_features_file: /content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/src-train.txt\n",
            "  train_labels_file: /content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/raw_data/tgt-train.txt\n",
            "eval:\n",
            "  batch_size: 32\n",
            "  batch_type: examples\n",
            "  early_stopping:\n",
            "    metric: bleu\n",
            "    min_improvement: 0.2\n",
            "    steps: 4\n",
            "  external_evaluators: bleu\n",
            "  length_bucket_width: 5\n",
            "infer:\n",
            "  batch_size: 32\n",
            "  batch_type: examples\n",
            "  length_bucket_width: 5\n",
            "model_dir: /content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/model\n",
            "params:\n",
            "  average_loss_in_time: false\n",
            "  beam_width: 4\n",
            "  learning_rate: 0.0002\n",
            "  num_hypotheses: 1\n",
            "  optimizer: Adam\n",
            "score:\n",
            "  batch_size: 64\n",
            "train:\n",
            "  batch_size: 64\n",
            "  batch_type: examples\n",
            "  length_bucket_width: 1\n",
            "  max_step: 500000\n",
            "  maximum_features_length: 80\n",
            "  maximum_labels_length: 80\n",
            "  sample_buffer_size: -1\n",
            "  save_summary_steps: 100\n",
            "\n",
            "2021-01-25 10:33:36.937881: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-01-25 10:33:36.938161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-25 10:33:36.938722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-01-25 10:33:36.938767: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-01-25 10:33:36.938817: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
            "2021-01-25 10:33:36.938841: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
            "2021-01-25 10:33:36.938864: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-01-25 10:33:36.938883: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-01-25 10:33:36.938901: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-01-25 10:33:36.938922: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-01-25 10:33:36.938943: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-01-25 10:33:36.939024: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-25 10:33:36.939571: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-25 10:33:36.940057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-01-25 10:33:36.943389: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-01-25 10:33:40.965257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-01-25 10:33:40.965311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "2021-01-25 10:33:40.965326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "2021-01-25 10:33:40.971367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-25 10:33:40.971953: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-25 10:33:40.972538: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-25 10:33:40.973023: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-01-25 10:33:40.973186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13960 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:No checkpoint to restore in /content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/model\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/summary/summary_iterator.py:31: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use eager execution and: \n",
            "`tf.data.TFRecordDataset(path)`\n",
            "INFO:tensorflow:Training on 1364 examples\n",
            "2021-01-25 10:33:43.175085: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "2021-01-25 10:33:43.180897: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "INFO:tensorflow:Number of model parameters: 71634664\n",
            "INFO:tensorflow:Number of model weights: 30 (trainable = 30, non trainable = 0)\n",
            "2021-01-25 10:34:04.999086: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
            "INFO:tensorflow:Saved checkpoint /content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/model/ckpt-1\n",
            "INFO:tensorflow:Step = 100 ; steps/s = 4.02, source words/s = 1064, target words/s = 1180 ; Learning rate = 0.000200 ; Loss = 6.215517\n",
            "INFO:tensorflow:Step = 200 ; steps/s = 3.99, source words/s = 1037, target words/s = 1148 ; Learning rate = 0.000200 ; Loss = 5.954324\n",
            "INFO:tensorflow:Step = 300 ; steps/s = 3.82, source words/s = 901, target words/s = 996 ; Learning rate = 0.000200 ; Loss = 5.386032\n",
            "INFO:tensorflow:Step = 400 ; steps/s = 4.22, source words/s = 1104, target words/s = 1223 ; Learning rate = 0.000200 ; Loss = 5.711170\n",
            "INFO:tensorflow:Step = 500 ; steps/s = 3.99, source words/s = 1007, target words/s = 1117 ; Learning rate = 0.000200 ; Loss = 5.015446\n",
            "INFO:tensorflow:Step = 600 ; steps/s = 3.79, source words/s = 948, target words/s = 1048 ; Learning rate = 0.000200 ; Loss = 5.185044\n",
            "INFO:tensorflow:Step = 700 ; steps/s = 4.11, source words/s = 1015, target words/s = 1123 ; Learning rate = 0.000200 ; Loss = 3.165246\n",
            "INFO:tensorflow:Step = 800 ; steps/s = 4.05, source words/s = 1041, target words/s = 1156 ; Learning rate = 0.000200 ; Loss = 5.428173\n",
            "INFO:tensorflow:Step = 900 ; steps/s = 3.81, source words/s = 991, target words/s = 1097 ; Learning rate = 0.000200 ; Loss = 5.296965\n",
            "INFO:tensorflow:Step = 1000 ; steps/s = 3.97, source words/s = 931, target words/s = 1027 ; Learning rate = 0.000200 ; Loss = 4.933107\n",
            "INFO:tensorflow:Step = 1100 ; steps/s = 4.21, source words/s = 1122, target words/s = 1243 ; Learning rate = 0.000200 ; Loss = 5.155172\n",
            "INFO:tensorflow:Step = 1200 ; steps/s = 3.84, source words/s = 985, target words/s = 1093 ; Learning rate = 0.000200 ; Loss = 1.586787\n",
            "INFO:tensorflow:Step = 1300 ; steps/s = 3.82, source words/s = 916, target words/s = 1015 ; Learning rate = 0.000200 ; Loss = 5.235528\n",
            "INFO:tensorflow:Step = 1400 ; steps/s = 4.10, source words/s = 1059, target words/s = 1170 ; Learning rate = 0.000200 ; Loss = 3.926923\n",
            "INFO:tensorflow:Step = 1500 ; steps/s = 4.05, source words/s = 1025, target words/s = 1136 ; Learning rate = 0.000200 ; Loss = 4.763162\n",
            "INFO:tensorflow:Step = 1600 ; steps/s = 3.80, source words/s = 962, target words/s = 1064 ; Learning rate = 0.000200 ; Loss = 5.079610\n",
            "INFO:tensorflow:Step = 1700 ; steps/s = 3.96, source words/s = 962, target words/s = 1064 ; Learning rate = 0.000200 ; Loss = 2.697699\n",
            "INFO:tensorflow:Step = 1800 ; steps/s = 4.11, source words/s = 1070, target words/s = 1189 ; Learning rate = 0.000200 ; Loss = 4.987210\n",
            "INFO:tensorflow:Step = 1900 ; steps/s = 3.98, source words/s = 1026, target words/s = 1135 ; Learning rate = 0.000200 ; Loss = 4.028838\n",
            "INFO:tensorflow:Step = 2000 ; steps/s = 3.93, source words/s = 933, target words/s = 1030 ; Learning rate = 0.000200 ; Loss = 4.730184\n",
            "INFO:tensorflow:Step = 2100 ; steps/s = 4.31, source words/s = 1141, target words/s = 1265 ; Learning rate = 0.000200 ; Loss = 4.754405\n",
            "INFO:tensorflow:Step = 2200 ; steps/s = 3.94, source words/s = 1002, target words/s = 1113 ; Learning rate = 0.000200 ; Loss = 2.792503\n",
            "INFO:tensorflow:Step = 2300 ; steps/s = 4.01, source words/s = 982, target words/s = 1083 ; Learning rate = 0.000200 ; Loss = 4.854733\n",
            "INFO:tensorflow:Step = 2400 ; steps/s = 4.13, source words/s = 1047, target words/s = 1161 ; Learning rate = 0.000200 ; Loss = 3.209277\n",
            "INFO:tensorflow:Step = 2500 ; steps/s = 4.02, source words/s = 1015, target words/s = 1128 ; Learning rate = 0.000200 ; Loss = 4.102511\n",
            "INFO:tensorflow:Step = 2600 ; steps/s = 3.73, source words/s = 949, target words/s = 1050 ; Learning rate = 0.000200 ; Loss = 2.945050\n",
            "INFO:tensorflow:Step = 2700 ; steps/s = 4.05, source words/s = 980, target words/s = 1081 ; Learning rate = 0.000200 ; Loss = 1.410368\n",
            "INFO:tensorflow:Step = 2800 ; steps/s = 4.30, source words/s = 1121, target words/s = 1245 ; Learning rate = 0.000200 ; Loss = 4.182327\n",
            "INFO:tensorflow:Step = 2900 ; steps/s = 3.80, source words/s = 996, target words/s = 1101 ; Learning rate = 0.000200 ; Loss = 3.801025\n",
            "INFO:tensorflow:Step = 3000 ; steps/s = 3.81, source words/s = 900, target words/s = 997 ; Learning rate = 0.000200 ; Loss = 4.417244\n",
            "INFO:tensorflow:Step = 3100 ; steps/s = 4.48, source words/s = 1180, target words/s = 1306 ; Learning rate = 0.000200 ; Loss = 3.125523\n",
            "INFO:tensorflow:Step = 3200 ; steps/s = 3.92, source words/s = 991, target words/s = 1101 ; Learning rate = 0.000200 ; Loss = 2.350253\n",
            "INFO:tensorflow:Step = 3300 ; steps/s = 3.95, source words/s = 978, target words/s = 1078 ; Learning rate = 0.000200 ; Loss = 3.038460\n",
            "INFO:tensorflow:Step = 3400 ; steps/s = 4.19, source words/s = 1051, target words/s = 1164 ; Learning rate = 0.000200 ; Loss = 0.440848\n",
            "INFO:tensorflow:Step = 3500 ; steps/s = 4.02, source words/s = 1027, target words/s = 1142 ; Learning rate = 0.000200 ; Loss = 3.463527\n",
            "INFO:tensorflow:Step = 3600 ; steps/s = 3.69, source words/s = 936, target words/s = 1035 ; Learning rate = 0.000200 ; Loss = 2.440761\n",
            "INFO:tensorflow:Step = 3700 ; steps/s = 3.84, source words/s = 919, target words/s = 1015 ; Learning rate = 0.000200 ; Loss = 0.501069\n",
            "INFO:tensorflow:Step = 3800 ; steps/s = 4.48, source words/s = 1192, target words/s = 1323 ; Learning rate = 0.000200 ; Loss = 3.376962\n",
            "INFO:tensorflow:Step = 3900 ; steps/s = 3.87, source words/s = 1007, target words/s = 1115 ; Learning rate = 0.000200 ; Loss = 2.986463\n",
            "INFO:tensorflow:Step = 4000 ; steps/s = 4.02, source words/s = 947, target words/s = 1047 ; Learning rate = 0.000200 ; Loss = 2.093786\n",
            "INFO:tensorflow:Step = 4100 ; steps/s = 4.33, source words/s = 1135, target words/s = 1257 ; Learning rate = 0.000200 ; Loss = 1.534665\n",
            "INFO:tensorflow:Step = 4200 ; steps/s = 3.96, source words/s = 998, target words/s = 1107 ; Learning rate = 0.000200 ; Loss = 1.635468\n",
            "INFO:tensorflow:Step = 4300 ; steps/s = 3.81, source words/s = 953, target words/s = 1056 ; Learning rate = 0.000200 ; Loss = 2.303113\n",
            "INFO:tensorflow:Step = 4400 ; steps/s = 4.09, source words/s = 1011, target words/s = 1117 ; Learning rate = 0.000200 ; Loss = 0.053801\n",
            "INFO:tensorflow:Step = 4500 ; steps/s = 4.13, source words/s = 1061, target words/s = 1178 ; Learning rate = 0.000200 ; Loss = 2.280571\n",
            "INFO:tensorflow:Step = 4600 ; steps/s = 3.91, source words/s = 1009, target words/s = 1117 ; Learning rate = 0.000200 ; Loss = 2.144739\n",
            "INFO:tensorflow:Step = 4700 ; steps/s = 3.90, source words/s = 924, target words/s = 1021 ; Learning rate = 0.000200 ; Loss = 2.013345\n",
            "INFO:tensorflow:Step = 4800 ; steps/s = 4.44, source words/s = 1180, target words/s = 1308 ; Learning rate = 0.000200 ; Loss = 1.582785\n",
            "INFO:tensorflow:Step = 4900 ; steps/s = 3.99, source words/s = 1023, target words/s = 1135 ; Learning rate = 0.000200 ; Loss = 0.409508\n",
            "INFO:tensorflow:Step = 5000 ; steps/s = 4.06, source words/s = 977, target words/s = 1078 ; Learning rate = 0.000200 ; Loss = 1.813476\n",
            "INFO:tensorflow:Saved checkpoint /content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/model/ckpt-5000\n",
            "INFO:tensorflow:Running evaluation for step 5000\n",
            "INFO:tensorflow:Evaluation predictions saved to /content/drive/MyDrive/Multilingual_Multimodal_Unversal_MT/Per_Eng_GRU_V1/model/eval/predictions.txt.5000\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/onmt-main\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/opennmt/bin/main.py\", line 231, in main\n",
            "    hvd=hvd)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/opennmt/runner.py\", line 245, in train\n",
            "    moving_average_decay=train_config.get(\"moving_average_decay\"))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/opennmt/training.py\", line 118, in __call__\n",
            "    early_stop = self._evaluate(evaluator, step, moving_average=moving_average)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/opennmt/training.py\", line 150, in _evaluate\n",
            "    evaluator(step)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/opennmt/evaluation.py\", line 317, in __call__\n",
            "    score = scorer(self._labels_file, output_path)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/opennmt/utils/scorers.py\", line 83, in __call__\n",
            "    bleu = sacrebleu.corpus_bleu(sys_stream, [ref_stream], force=True)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sacrebleu/compat.py\", line 36, in corpus_bleu\n",
            "    sys_stream, ref_streams, use_effective_order=use_effective_order)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sacrebleu/metrics/bleu.py\", line 276, in corpus_score\n",
            "    if any(len(ref_stream) != len(sys_stream) for ref_stream in ref_streams):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/sacrebleu/metrics/bleu.py\", line 276, in <genexpr>\n",
            "    if any(len(ref_stream) != len(sys_stream) for ref_stream in ref_streams):\n",
            "TypeError: object of type 'GFile' has no len()\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}